{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "avaIeyLcDF7F"
      },
      "source": [
        "#Importamos las librerías para pre-procesar el set de datos\r\n",
        "import tensorflow as tf \r\n",
        "import warnings\r\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\r\n",
        "import pandas as pd\r\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Activation\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4zqEwnNwbQO"
      },
      "source": [
        "El set de datos que vamos a utilizar es el conocido Iris Dataset. Vamos a cargar dos dataframes, el de entrenamiento y el de testeo.\r\n",
        "Las columnas serán 5: Sepal Length, Sepal Width, Petal Length, Petal Width y Species. \r\n",
        "La columna de Species será la columna que debemos predecir, y tomará los valores: Setosa, Versicolor o Virginica (0,1,2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07YSiBGcwW-y"
      },
      "source": [
        "train_path = tf.keras.utils.get_file(\"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\r\n",
        "test_path = tf.keras.utils.get_file(\"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\r\n",
        "\r\n",
        "column_names = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth','Species']\r\n",
        "X_columns = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\r\n",
        "Y_column = ['Species']\r\n",
        "species = ['Setosa', 'Versicolor', 'Virginica']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEXzbRCIdHbc"
      },
      "source": [
        "df_train = pd.read_csv(train_path, names=column_names, header=0)\r\n",
        "df_test = pd.read_csv(test_path, names=column_names, header=0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "r0a--ape4VK5",
        "outputId": "6078bc12-4e8f-42cc-81f7-bcdb2b5a3052"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
              "0          6.4         2.8          5.6         2.2        2\n",
              "1          5.0         2.3          3.3         1.0        1\n",
              "2          4.9         2.5          4.5         1.7        2\n",
              "3          4.9         3.1          1.5         0.1        0\n",
              "4          5.7         3.8          1.7         0.3        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FatYEL7dhni2",
        "outputId": "4c9adaf8-fe59-4527-cc2f-ba2a5ee09a2a"
      },
      "source": [
        "#Vamos a separar el set de datos en X e Y. \r\n",
        "\r\n",
        "X_train= df_train[X_columns]\r\n",
        "Y_train= df_train[Y_column]\r\n",
        "\r\n",
        "X_test = df_test[X_columns]\r\n",
        "Y_test = df_test[Y_column]\r\n",
        "\r\n",
        "print(X_train.shape)\r\n",
        "print(X_test.shape)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(120, 1)\n",
            "(30, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Species\n",
              "2          42\n",
              "0          42\n",
              "1          36\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv5ssw_yy_I2"
      },
      "source": [
        "Vamos a visualizar los datos con un plot básico simplemente para ver la distribución de categorías. Esto es importante ya que nuestro modelo debe ser entrenado con un número de datos similar en cada categoría para evitar el overfitting, es decir, que se sobre-entrene para una determinada categoría y como consecuencia nos ofrezca resultados pobres a la hora de hacer predicciones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "j0t4ZleKzh33",
        "outputId": "0042d309-38c5-4e83-af98-19daac5787db"
      },
      "source": [
        "fig, axes = plt.subplots(1,2,figsize=(20,6)) \r\n",
        "# Plot del set de entrenamiento\r\n",
        "sns.countplot(Y_train.to_numpy(dtype=np.float64).reshape(-1), ax=axes[0]) #Convertimos el DF en un array numpy con dtype float.\r\n",
        "axes[0].set_title('Distribución de los ejemplos de entrenamiento ')\r\n",
        "axes[0].set_xlabel('Categorías')\r\n",
        "axes[0].set_ylabel('Cantidad')\r\n",
        "# Plot del set de testeo\r\n",
        "sns.countplot(Y_test.to_numpy(dtype=np.float64).reshape(-1), ax=axes[1])\r\n",
        "axes[1].set_title('Distribución de los ejemplos de testeo')\r\n",
        "axes[1].set_xlabel('Categorías')\r\n",
        "axes[1].set_ylabel('Cantidad')\r\n",
        "\r\n",
        "print(Y_train.value_counts())\r\n",
        "print(Y_test.value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Species\n",
            "2          42\n",
            "0          42\n",
            "1          36\n",
            "dtype: int64\n",
            "Species\n",
            "1          14\n",
            "2           8\n",
            "0           8\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8r3fmh70jkU"
      },
      "source": [
        "A continuación podremos definir nuestro modelo. Pero antes, debemos pre-procesar las categorías de las especies y aplicar OneHotEncoding. Esto se puede hacer automáticamente con keras. \r\n",
        "Lo que queremos hacer es pasar de la siguiente representación: \\\\\r\n",
        "[0, 1, 2]  \\\\\r\n",
        "a la representación \\\\\r\n",
        "[ [1, 0, 0], [0, 1, 0], [0, 0, 1] ] \\\\\r\n",
        "\r\n",
        "Así tendremos una representación binaria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYm1M13c1IFa"
      },
      "source": [
        "Y_train_OH = keras.utils.to_categorical(Y_train,num_classes = 3)\r\n",
        "Y_test_OH = keras.utils.to_categorical(Y_test, num_classes= 3) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_AEAMorhw21"
      },
      "source": [
        "#Ahora definimos nuestro modelo a través de keras\r\n",
        "model = Sequential([\r\n",
        "                    Dense(64, input_shape=X_train.shape[1:],activation='relu'), #Primera capa con 64 neuronas\r\n",
        "                    Dropout(0.25), #Desactivamos neuronas arbitrariamente\r\n",
        "                    Dense(32, activation='relu'), #Capa con 32 neuronas\r\n",
        "                    Dropout(0.25),\r\n",
        "                    Dense(16, activation='relu'), #Capa con 16 neuronas\r\n",
        "                    Dropout(0.25),\r\n",
        "                    Dense(units=3 ,activation='softmax') #Capa de salida con activación Softmax. En este caso hago explícito el units para \r\n",
        "                                                          #concretar que son 3 categorías.\r\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xHSdTYG9nw_"
      },
      "source": [
        "#Seleccionamos un método para optimizar. Escogeré el optimizador Adam pero hay otras alternativas como el SGD o el RMS\r\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "model.compile(optimizer=optimizer, loss=\"CategoricalCrossentropy\", metrics=['accuracy']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEm5Gu6694Wk",
        "outputId": "bf1efcdb-9c88-47e1-9aac-c7139c2a7f7a"
      },
      "source": [
        "train_NN = model.fit(X_train, Y_train_OH, batch_size=32, epochs=150, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "4/4 [==============================] - 1s 4ms/step - loss: 1.7364 - accuracy: 0.2896\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1980 - accuracy: 0.4098\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.2135 - accuracy: 0.3619\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0520 - accuracy: 0.4756\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.1209 - accuracy: 0.4721\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.0352 - accuracy: 0.5121\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.9520 - accuracy: 0.5277\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.0120 - accuracy: 0.5104\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8862 - accuracy: 0.6467\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8918 - accuracy: 0.5825\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.8547 - accuracy: 0.5813\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8394 - accuracy: 0.5794\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8080 - accuracy: 0.5890\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8681 - accuracy: 0.5892\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.6300\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.8042 - accuracy: 0.6315\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7559 - accuracy: 0.5392\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.7096\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.6525\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7102\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.6417\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5777 - accuracy: 0.7471\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6965\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.6656\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5759 - accuracy: 0.7675\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7290\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5727 - accuracy: 0.7119\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.6585\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.6683\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.6819\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.5306 - accuracy: 0.6992\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7375\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7865\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7275\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7667\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7371\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.6792\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4899 - accuracy: 0.7629\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7704\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.7592\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7585\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.7202\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8010\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7406\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7521\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7958\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.7860\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7704\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8410\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7706\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.8183\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.7890\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3987 - accuracy: 0.8033\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7956\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7744\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.7754\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3876 - accuracy: 0.7992\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.7698\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8269\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3655 - accuracy: 0.8142\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.7981\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8342\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.8025\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3513 - accuracy: 0.8302\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8473\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8142\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8348\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3042 - accuracy: 0.8894\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8871\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3045 - accuracy: 0.8479\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8498\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8196\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8819\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8767\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8879\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8558\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 0.8610\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8598\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8917\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.9040\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2391 - accuracy: 0.9273\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2866 - accuracy: 0.8775\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2778 - accuracy: 0.9008\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9371\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2674 - accuracy: 0.9144\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.8208\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8400\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2769 - accuracy: 0.9123\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8906\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.3098 - accuracy: 0.8910\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.9337\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2819 - accuracy: 0.8983\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8865\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2973 - accuracy: 0.8931\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8879\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2129 - accuracy: 0.9254\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2430 - accuracy: 0.9212\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2575 - accuracy: 0.8940\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2288 - accuracy: 0.9319\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2108 - accuracy: 0.9450\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8425\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2403 - accuracy: 0.8952\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2177 - accuracy: 0.9046\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2054 - accuracy: 0.9069\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1521 - accuracy: 0.9881\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2753 - accuracy: 0.8933\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.9496\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2008 - accuracy: 0.9165\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9298\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2046 - accuracy: 0.9625\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2354 - accuracy: 0.8948\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2154 - accuracy: 0.9106\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1857 - accuracy: 0.9210\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9246\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2651 - accuracy: 0.8983\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2119 - accuracy: 0.9167\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9508\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9379\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2187 - accuracy: 0.9019\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1499 - accuracy: 0.9742\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1985 - accuracy: 0.9369\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2435 - accuracy: 0.9040\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1768 - accuracy: 0.9454\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1830 - accuracy: 0.9471\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1415 - accuracy: 0.9581\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2254 - accuracy: 0.9350\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9223\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1931 - accuracy: 0.9277\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 0.9475\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9252\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1365 - accuracy: 0.9538\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9529\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1666 - accuracy: 0.9337\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1653 - accuracy: 0.9621\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1213 - accuracy: 0.9685\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9223\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1742 - accuracy: 0.9365\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1972 - accuracy: 0.9250\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1402 - accuracy: 0.9565\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9465\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.9244\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9592\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9413\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2486 - accuracy: 0.9410\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9504\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.8583\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1131 - accuracy: 0.9946\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9210\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.9423\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1386 - accuracy: 0.9858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAcXIap6-OcE"
      },
      "source": [
        "#Vamos a hacer las predicciones y convertimos las predicciones binarias a categóricas\r\n",
        "Y_pred = model.predict(X_test)\r\n",
        "Y_pred_categories = np.argmax(Y_pred, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn2HC5hICGTY",
        "outputId": "165cf8fc-63cb-4267-fd87-f2c9a92850d5"
      },
      "source": [
        "scores = model.evaluate(X_test, Y_test_OH)\r\n",
        "print(scores[0])\r\n",
        "print(scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0962 - accuracy: 0.9667\n",
            "0.0961693748831749\n",
            "0.9666666388511658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6GE1A7qCykY"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYCjU1U7C2dU",
        "outputId": "05be7212-d20d-4fd9-ee29-9a3c7cfef231"
      },
      "source": [
        "print(classification_report(Y_test, Y_pred_categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      0.93      0.96        14\n",
            "           2       0.89      1.00      0.94         8\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.96      0.98      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csZbONtg451y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}