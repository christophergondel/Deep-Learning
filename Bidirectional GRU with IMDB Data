{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-21T19:01:03.507226Z","iopub.execute_input":"2022-02-21T19:01:03.507556Z","iopub.status.idle":"2022-02-21T19:01:03.538649Z","shell.execute_reply.started":"2022-02-21T19:01:03.507451Z","shell.execute_reply":"2022-02-21T19:01:03.537944Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import required libraries and modules","metadata":{}},{"cell_type":"code","source":"import csv\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:01:07.619045Z","iopub.execute_input":"2022-02-21T19:01:07.619622Z","iopub.status.idle":"2022-02-21T19:01:12.587150Z","shell.execute_reply.started":"2022-02-21T19:01:07.619583Z","shell.execute_reply":"2022-02-21T19:01:12.586403Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Now let's define some hyperparameters","metadata":{}},{"cell_type":"code","source":"vocab_size = 10000\nembedding_dim = 16 #Vector dimension for the word encoding\nmax_length = 120\ntrunc_type = \"post\"\npadding_type = \"post\" #Type of padding for each sentence\noov_tok = \"<OOV>\" #OOV = Out Of Vocabulary\ntraining_portion = 0.75","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:01:12.588693Z","iopub.execute_input":"2022-02-21T19:01:12.588928Z","iopub.status.idle":"2022-02-21T19:01:12.596258Z","shell.execute_reply.started":"2022-02-21T19:01:12.588895Z","shell.execute_reply":"2022-02-21T19:01:12.594530Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data processing","metadata":{}},{"cell_type":"markdown","source":"## Reading data and creating X and Y sets","metadata":{}},{"cell_type":"code","source":"#Let's first define a list of stopwords that we will ignore without\n#sacrificing the actual meaning of the sentence\nstopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n\n#Now let's create the lists for the X and Y:\nsentences = []#X\nlabels = []#Y\n\nwith open(\"/kaggle/input/imdb-movie-ratings-sentiment-analysis/movie.csv\") as csvfile:\n    reader = csv.reader(csvfile, delimiter= ',')\n    next(reader)\n    \n    for row in reader: #Let's delete the stopwords from the dataset\n        labels.append(row[1])\n        sentence = row[0]\n        for word in stopwords:\n            token = \" \" + word + \" \"\n            sentence = sentence.replace(token, \" \")\n        sentences.append(sentence)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:10:22.579559Z","iopub.execute_input":"2022-02-21T19:10:22.580253Z","iopub.status.idle":"2022-02-21T19:10:39.371742Z","shell.execute_reply.started":"2022-02-21T19:10:22.580213Z","shell.execute_reply":"2022-02-21T19:10:39.370996Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Train/Test Splitting","metadata":{}},{"cell_type":"code","source":"training_sentences = sentences[0 : int(len(sentences)*training_portion)]\ntest_sentences = sentences[int(len(sentences)*training_portion) : ]\n\ntraining_labels = labels[0 :  int(len(labels)*training_portion)]\ntest_labels = labels[int(len(labels)*training_portion) : ]","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:11:01.760273Z","iopub.execute_input":"2022-02-21T19:11:01.760937Z","iopub.status.idle":"2022-02-21T19:11:01.767399Z","shell.execute_reply.started":"2022-02-21T19:11:01.760900Z","shell.execute_reply":"2022-02-21T19:11:01.766716Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Defining the Tokenizer and converting texts to sequences","metadata":{}},{"cell_type":"code","source":"#First we create a Tokenizer object with num_words as the size of the vocabulary.\n#Then, we fit the tokenizer on our training corpus.\ntokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\ntokenizer.fit_on_texts(training_sentences)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:11:04.411156Z","iopub.execute_input":"2022-02-21T19:11:04.411732Z","iopub.status.idle":"2022-02-21T19:11:08.478985Z","shell.execute_reply.started":"2022-02-21T19:11:04.411691Z","shell.execute_reply":"2022-02-21T19:11:08.478218Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Once we have completed the fitting, we convert the\n#training and testing sentences to padded sequences.\n\ntraining_sequences = tokenizer.texts_to_sequences(training_sentences)\ntraining_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type)\n\ntesting_sequences = tokenizer.texts_to_sequences(test_sentences)\ntesting_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:11:08.480438Z","iopub.execute_input":"2022-02-21T19:11:08.480708Z","iopub.status.idle":"2022-02-21T19:11:12.687443Z","shell.execute_reply.started":"2022-02-21T19:11:08.480672Z","shell.execute_reply":"2022-02-21T19:11:12.686717Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Creating the Model + Training","metadata":{}},{"cell_type":"markdown","source":"## Model Structure","metadata":{}},{"cell_type":"markdown","source":"We are going to create a Sequential model that will contain the following layers:\n1. Embedding Layer to represent words as vectors.\n2. Bidirectional GRUto \"take into account the whole context\"\n3. Dense Layer with 24 neurons and a relu activation function\n4. Dense Layer with 1 neuron and a sigmoid activation function.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n    tf.keras.layers.Dense(24, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(loss='binary_crossentropy',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'], )\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:11:28.799346Z","iopub.execute_input":"2022-02-21T19:11:28.799923Z","iopub.status.idle":"2022-02-21T19:11:29.162894Z","shell.execute_reply.started":"2022-02-21T19:11:28.799883Z","shell.execute_reply":"2022-02-21T19:11:29.162161Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Creating a CallBack","metadata":{}},{"cell_type":"code","source":"CallBack = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\",\n    min_delta=0.005,\n    patience=2,\n    mode=\"auto\",\n    restore_best_weights=False\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:11:32.250327Z","iopub.execute_input":"2022-02-21T19:11:32.250615Z","iopub.status.idle":"2022-02-21T19:11:32.256380Z","shell.execute_reply.started":"2022-02-21T19:11:32.250585Z","shell.execute_reply":"2022-02-21T19:11:32.254050Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"#First we're converting the data to numpy arrays\ntraining_padded = np.array(training_padded)\ntraining_labels = np.array(training_labels).astype(float)\ntesting_padded = np.array(testing_padded)\ntesting_labels = np.array(test_labels).astype(float)","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:11:34.405430Z","iopub.execute_input":"2022-02-21T19:11:34.406278Z","iopub.status.idle":"2022-02-21T19:11:34.448924Z","shell.execute_reply.started":"2022-02-21T19:11:34.406240Z","shell.execute_reply":"2022-02-21T19:11:34.448176Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Now, let's train the model\nnum_epochs = 20\nhistory = model.fit(training_padded, training_labels.astype(float),\\\n                    epochs=num_epochs, validation_data=(testing_padded, testing_labels.astype(float)),\n                   verbose=1, callbacks= [CallBack])","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:11:38.432817Z","iopub.execute_input":"2022-02-21T19:11:38.433350Z","iopub.status.idle":"2022-02-21T19:12:40.979170Z","shell.execute_reply.started":"2022-02-21T19:11:38.433308Z","shell.execute_reply":"2022-02-21T19:12:40.978412Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def plot_graphs(history, string):\n  plt.plot(history.history[string])\n  plt.plot(history.history['val_'+string])\n  plt.xlabel(\"Epochs\")\n  plt.ylabel(string)\n  plt.legend([string, 'val_'+string])\n  plt.show()\n\nplot_graphs(history, 'accuracy')\nplot_graphs(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2022-02-21T19:12:52.359628Z","iopub.execute_input":"2022-02-21T19:12:52.359880Z","iopub.status.idle":"2022-02-21T19:12:52.772652Z","shell.execute_reply.started":"2022-02-21T19:12:52.359853Z","shell.execute_reply":"2022-02-21T19:12:52.771983Z"},"trusted":true},"execution_count":18,"outputs":[]}]}
